{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f269ad4",
   "metadata": {},
   "source": [
    "# Image Classification with CNN\n",
    "The idea of this model is to class the animals into their own species based in a few features  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d26c8",
   "metadata": {},
   "source": [
    "### Load Dataset and Import First Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nvidia.cudnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\"\"\"\n",
    "Download dataset\n",
    "\"\"\"\n",
    "# Load CIFAR-10 dataset and split into training data and tests data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a07719",
   "metadata": {},
   "source": [
    "### Normalize Data / Clean up (Filter Animal classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animal classes in CIFAR-10: 2 (bird), 3 (cat), 4 (deer), 5 (dog), 6 (frog), 7 (horse)\n",
    "animal_classes = [2, 3, 4, 5, 6, 7]\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Creating a boolean mask to filter only animal classes\n",
    "train_mask = np.isin(y_train, animal_classes)\n",
    "test_mask  = np.isin(y_test, animal_classes)\n",
    "\n",
    "x_train_animals = x_train[train_mask.flatten()]\n",
    "y_train_animals = y_train[train_mask.flatten()]\n",
    "x_test_animals  = x_test[test_mask.flatten()]\n",
    "y_test_animals  = y_test[test_mask.flatten()]\n",
    "\n",
    "# Relabel classes\n",
    "label_map = {2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5}\n",
    "y_train_animals = np.vectorize(label_map.get)(y_train_animals)\n",
    "y_test_animals  = np.vectorize(label_map.get)(y_test_animals)\n",
    "\n",
    "# Normalize Data\n",
    "x_train_animals = x_train_animals.astype(\"float32\") / 255.0\n",
    "x_test_animals  = x_test_animals.astype(\"float32\") / 255.0\n",
    "\n",
    "## Visualisize images\n",
    "# read call lables\n",
    "class_names = np.unique(y_train_animals)\n",
    "fig, axes = plt.subplots(5, 10, figsize=(15, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    # Get indices for images of class i\n",
    "    indices = np.where(y_train_animals == i)[0]\n",
    "    # Randomly select 10 indices from the class\n",
    "    random_indices = np.random.choice(indices, size=10, replace=False)\n",
    "    \n",
    "    for j, idx in enumerate(random_indices):\n",
    "        # Plot the image in the appropriate subplot\n",
    "        axes[i, j].imshow(x_train_animals[idx])\n",
    "        axes[i, j].axis('off')  # Hide axis ticks\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel(class_names[i], fontsize=12)  # Label the class\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "y_train_animals = to_categorical(y_train_animals, 6)\n",
    "y_test_animals  = to_categorical(y_test_animals, 6)\n",
    "\n",
    "# Verify if shapes correspond to expectations\n",
    "print(\"x_train_animals shape:\", x_train_animals.shape)\n",
    "print(\"y_train_animals shape:\", y_train_animals.shape)\n",
    "print(\"x_test_animals shape:\", x_test_animals.shape)\n",
    "print(\"y_test_animals shape:\", y_test_animals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae406ec2",
   "metadata": {},
   "source": [
    "### Build Model And Train It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921376e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "vgg_model = Sequential()\n",
    "\n",
    "# add Convolutional-Layer \n",
    "vgg_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "vgg_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# add MaxPooling-Layer\n",
    "vgg_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# add 2 more Convolutional-Layer \n",
    "vgg_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vgg_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# improve training speed and stability\n",
    "vgg_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# add MaxPooling-Layer\n",
    "vgg_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# Flatten output\n",
    "vgg_model.add(Flatten())\n",
    "\n",
    "# add Dense-Layer with 128 units\n",
    "vgg_model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add dropout after dense-layer to  prevent overfitting\n",
    "vgg_model.add(Dropout(0.5))\n",
    "\n",
    "# add classification layer (5 classes)\n",
    "vgg_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train settings\n",
    "batch_size = 512\n",
    "num_classes = 6\n",
    "epochs = 45\n",
    "\n",
    "\n",
    "adam_opt = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# compile the model\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history_m3 = vgg_model.fit(x_train_animals, y_train_animals, \n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test_animals, y_test_animals))\n",
    "\n",
    "\n",
    "# predict output for test data\n",
    "predictions = vgg_model.predict(x_test_animals)\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# print confusion matrix\n",
    "gt = np.argmax(y_test_animals, axis=1)\n",
    "confusion_matrix(gt, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
